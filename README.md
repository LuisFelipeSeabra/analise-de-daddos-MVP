# MVP - Machine learning

**[Desafio kaggle](https://www.kaggle.com/datasets/kelvinkelue/credit-card-fraud-prediction)**

## Defini√ß√£o do problema üî•

Ao trabalhar na previs√£o de fraudes de cart√£o de cr√©dito, utilizaremos um conjunto de dados com recursos relacionados a detalhes de transa√ß√µes sobre titulares de cart√µes. O objetivo √© classificar as transa√ß√µes como fraudulentas ou leg√≠timas. 
Tal problema trata-se de aprendizado supervisionado, que √© um tipo de t√©cnica de machine learning (aprendizado de m√°quina) onde um modelo √© treinado usando dados rotulados. Em outras palavras, os dados de treinamento incluem tanto as entradas quanto as sa√≠das desejadas.

## Descri√ß√£o do conjunto de dados üìú

Este conjunto de dados oferece uma variedade de atributos valiosos para uma an√°lise abrangente. 
Ele cont√©m 555.719 inst√¢ncias e 22 atributos, uma mistura de tipos de dados categ√≥ricos e num√©ricos. 
√â importante ressaltar que o conjunto de dados est√° completo sem valores nulos.
Aqui est√° uma an√°lise dos atributos:

* Trans_date_trans_time:Timestamp da transa√ß√£o (data e hora).
* Cc_num: N√∫mero de identifica√ß√£o exclusivo do cliente.
* Comerciante: O comerciante envolvido na transa√ß√£o.
* Categoria: Tipo de transa√ß√£o (por exemplo, pessoal, assist√™ncia infantil).
* Valor: Valor da transa√ß√£o.
* Primeiro: Primeiro nome do titular do cart√£o.
* Sobrenome do titular do cart√£o.
* G√™nero: g√™nero do titular do cart√£o.
* Rua: Endere√ßo do titular do cart√£o.
* Cidade: Cidade de resid√™ncia do titular do cart√£o.
* Estado: Estado de resid√™ncia do titular do cart√£o.
* CEP: CEP do titular do cart√£o.
* Lat: Latitude da localiza√ß√£o do titular do cart√£o.
* Long: Longitude da localiza√ß√£o do titular do cart√£o.
* City_pop: Popula√ß√£o da cidade do titular do cart√£o.
* Cargo: Cargo do titular do cart√£o.
* Dob: Data de nascimento do titular do cart√£o.
* Trans_num: identificador exclusivo da transa√ß√£o.
* Unix_time: carimbo de data/hora da transa√ß√£o (formato Unix).
* Merch_lat:Localiza√ß√£o do comerciante (latitude).
* Merch_long: localiza√ß√£o do comerciante (longitude).
* Is_fraud: Indicador de transa√ß√£o fraudulenta (1 = fraude, 0 = leg√≠tima). Esta √© a vari√°vel alvo para fins de classifica√ß√£o.

## Prepara√ß√£o de Dados ‚òïÔ∏è

Utilizou-se algumas t√©cnicas, durante o projeto, como:
#### One-hot Encoding
O One-Hot Encoding √© uma t√©cnica de pr√©-processamento de dados que converte vari√°veis categ√≥ricas em bin√°rios. Em outras palavras, ele cria uma nova coluna para cada valor √∫nico presente na vari√°vel categ√≥rica e atribui o valor 1 √† coluna correspondente ao valor presente e 0 no resto das colunas

#### Label  Encoding
Label Encoding consiste em converter as classes categ√≥ricas em n√∫meros que as representam (ex: masculino/feminino s√£o convertidos em 0/1, Brasil/EUA/Jap√£o ser√£o convertidos em 0/1/2, etc.). 

#### Balancemaneto da base com SMOTE
A SMOTE (t√©cnica de sobreamostragem minorit√°ria sint√©tica) √© uma t√©cnica estat√≠stica para aumentar o n√∫mero de casos em seu conjunto de um modo equilibrado. O componente funciona gerando novas inst√¢ncias de casos minorit√°rios existentes que voc√™ fornece como entrada.

#### Transformacao de datas de anivers√°rio em idade
A transforma√ß√£o de datas em idade √© importante, pois permite que os algoritmos matem√°ticos e estat√≠sticos funcionem corretamente. Esta transforma√ß√£o facilita a modelagem, melhora a efici√™ncia computacional, e possibilita uma an√°lise quantitativa detalhada.

#### Verifica√ß√£o de valores nulos
√â importante avaliar valores nulos no dataset pois podem causar Distor√ß√£o dos Resultados, Problemas com Processamento de Dados e Problemas de Performance e Efici√™ncia do modelo.

## An√°lise de dados ‚òïÔ∏è

### Resumo estat√≠stico dos atributos num√©ricos:
#### Unnamed: 0 
M√≠nimo: 0
M√°ximo: 555718
M√©dia: 277859
Desvio Padr√£o: 160422.40
Mediana: 277859
Moda: N/A
Valores Ausentes: 0
Observa√ß√£o: A m√©dia e a mediana s√£o aproximadamente iguais, o que √© esperado em uma sequ√™ncia num√©rica simples.

#### amt
M√≠nimo: 1.00
M√°ximo: 22768.11
M√©dia: 69.39
Desvio Padr√£o: 156.75
Mediana: 47.29
Moda: N/A 
Valores Ausentes: 0
Observa√ß√£o: A m√©dia √© significativamente menor do que o valor m√°ximo, indicando uma distribui√ß√£o com valores extremos (outliers) que afetam a m√©dia. O desvio padr√£o √© alto, refletindo a variabilidade dos montantes das transa√ß√µes.

#### lat (Latitude)
M√≠nimo: 20.027100
M√°ximo: 65.689900
M√©dia: 38.54
Desvio Padr√£o: 5.06
Mediana: 39.37
Moda: N/A 
Valores Ausentes: 0
Observa√ß√£o: Latitude √© relativamente est√°vel, com uma mediana pr√≥xima da m√©dia e um desvio padr√£o moderado, indicando que as transa√ß√µes est√£o concentradas em uma faixa geogr√°fica relativamente pequena.

#### long (Longitude)
M√≠nimo: -165.672300
M√°ximo: -67.950300
M√©dia: -90.23
Desvio Padr√£o: 13.72
Mediana: -87.48
Moda: N/A 
Valores Ausentes: 0
Observa√ß√£o: Longitude tamb√©m apresenta uma mediana pr√≥xima da m√©dia, com uma varia√ß√£o significativa. A longitude negativa sugere uma localiza√ß√£o predominantemente no hemisf√©rio ocidental.

#### city_pop (Popula√ß√£o da Cidade)
M√≠nimo: 23
M√°ximo: 2906700
M√©dia: 88221.89
Desvio Padr√£o: 300390.87
Mediana: 2408
Moda: N/A 
Valores Ausentes: 0
Observa√ß√£o: A m√©dia √© muito maior que a mediana, indicando que a distribui√ß√£o √© altamente enviesada para a direita com muitos outliers de cidades muito populosas.

#### is_fraud (Fraude)
M√≠nimo: 0
M√°ximo: 1
M√©dia: 0.00386
Desvio Padr√£o: 0.06201
Mediana: 0
Moda: 0
Valores Ausentes: 0
Observa√ß√£o: A vari√°vel is_fraud √© altamente desbalanceada, com uma grande maioria de transa√ß√µes n√£o fraudulentas (0) e uma pequena fra√ß√£o de transa√ß√µes fraudulentas (1). A m√©dia indica a propor√ß√£o de fraudes no conjunto de dados.

### Valores faltantes:
N√£o h√° valores faltantes ou zerados no dataset. 

## Modelagem e treinamento üéâ

Foram utilizados os seguintes para treinar e testar:

modelo_knn = dict(nome = "KNN", modelo = KNeighborsClassifier())
modelo_cart = dict(nome = "CART", modelo = DecisionTreeClassifier())
modelo_nb = dict(nome = "NB", modelo = GaussianNB())
modelo_svm = dict(nome = "SVM", modelo = SVC())

Divisao da base entre teste e treino foi de 80/20

#### Utilizamos validacao cruzada:
Na valida√ß√£o cruzada k-fold, voc√™ divide os dados de entrada em subconjuntos de dados k (tamb√©m chamados de folds). Voc√™ treina um modelo de ML em todos, menos em um (k-1) dos conjuntos de dados e, em seguida, avalia o modelo no conjunto de dados que n√£o foi usado para treinamento.

## Avalia√ß√£o de Resultados ü¶Ñ


#### One-hot Encoder
Utilizando one hot encoder, atingimos os seguintes valores de treino:
KNN: 0.996064 (0.000072)
CART: 0.996720 (0.000045)!
NB: 0.939459 (0.000839)
SVM: 0.996084 (0.000097)

J√° para testes:
Acur√°cio do modelo KNN: 0.996014
Acur√°cio do modelo CART: 0.996869!
Acur√°cio do modelo NB: 0.940393
Acur√°cio do modelo SVM: 0.996293


#### Label Encoder
Utilizando label encoder, atingimos os seguintes valores de treino:
KNN: 0.996156 (0.000061)
CART: 0.996648 (0.000094)!
NB: 0.992168 (0.000859)
SVM: 0.996082 (0.000094)

J√° para testes:
Acur√°cio do modelo KNN: 0.996257
Acur√°cio do modelo CART: 0.996779!
Acur√°cio do modelo NB: 0.992559
Acur√°cio do modelo SVM: 0.996284


#### SMOTE + label encoder
Utilizando SMOTE para balancear a base, atingimos os seguintes valores de treino:
KNN: 0.986253 (0.000079)
CART: 0.988424 (0.000028)!
NB: 0.814953 (0.003902)

J√° para testes:
Acur√°cio do modelo KNN: 0.980197
Acur√°cio do modelo CART: 0.988169!
Acur√°cio do modelo NB: 0.976373


## Conclus√£o üî•

Em todos os testes e treinamentos, CART obteve a maior acur√°cia!

Por√©m, KNN(utilizando SMOTE) conseguiu o melhor desempenho em encontrar fraudes(357), em contrapartida, apresentou muitos falsos positivos(2132). 
Esse modelo previu, corretamente, que 108586 casos n√£o eram fraudes e errou apenas 69(falso negativo).

J√° o Cart(one-hot encoder), com acur√°cia de 0.996869, encontrou 252 fraudes e apresentou poucos falsos positivos(174).
Esse modelo previu, corretamente, que 110544 casos n√£o eram fraudes e encontrou 174 falsos negativos.

A melhor opcao encontrada para evitar fraudes foi o KNN(utilizando Smote), uma vez que conseguiu prever o maior numero de fraudes, cerca de 357 casos.
Apesar da quantidade de falsos positivos, o modelo foi o que mais previu fraudes e o que menos apresentou casos falso negativo: 69.